{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PROJ_LIB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a7ce48283997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeodesic\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgeodesic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/mpl_toolkits/basemap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m# create dictionary that maps epsg codes to Basemap kwargs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m \u001b[0mpyproj_datadir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROJ_LIB'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0mepsgf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyproj_datadir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'epsg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0mepsg_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PROJ_LIB'"
     ]
    }
   ],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# Geographic data\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic as geodesic\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"./all/basic_filter-\"\n",
    "PATH = \"./all/basic_filter_drop_datetime\"\n",
    "\n",
    "# read whole file use None\n",
    "# ROWS = None \n",
    "ROWS = 500_000\n",
    "\n",
    "LEFT_BOTTOM_CITY = 'Tennessee'\n",
    "RIGHT_TOP_CITY = 'Maine'\n",
    "\n",
    "NYC_LONGITUDE = (-74.256436, -73.699733)\n",
    "NYC_LATITUDE = (40.495029, 40.915592)\n",
    "\n",
    "JFK_LONGITUDE = (-73.789185, -73.775291)\n",
    "JFK_LATITUDE = (40.641960, 40.649562)\n",
    "\n",
    "# Taxicab Rate of Fare\n",
    "MILEAGE = 0.4 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read feather\n",
    "\n",
    "# basic_filter_df = pd.read_feather(PATH+str(ROWS))\n",
    "basic_filter_df = pd.read_feather(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent='city')\n",
    "LEFT_BOTTOM_BOUNDARY = geolocator.geocode(LEFT_BOTTOM_CITY)\n",
    "RIGHT_TOP_BOUNDARY = geolocator.geocode(RIGHT_TOP_CITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_pearson_corr_result(df, title):\n",
    "    print('{title}, Pearson correlation coef. of:'.format(title=title))\n",
    "    format_rule = '    {0:30}'\n",
    "    # Euclidean distance of the ride and the taxi fare\n",
    "    print(format_rule.format('dist and fare: '), \\\n",
    "          df['dist'].corr(df['fare_amount']))\n",
    "    # time of day and distance traveled\n",
    "    print(format_rule.format('time of day and dist: '), \\\n",
    "          df['hour'].corr(df['dist']))\n",
    "    # time of day and the taxi fare\n",
    "    print(format_rule.format('time of day and fare: '), \\\n",
    "          df['hour'].corr(df['fare_amount']))\n",
    "    \n",
    "def basic_visualization_result(df):\n",
    "    df.plot(kind='scatter', x='dist', y='fare_amount')\n",
    "    df.plot(kind='scatter', x='dist', y='hour')\n",
    "    df.plot(kind='scatter', x='hour', y='fare_amount')\n",
    "    \n",
    "def compare_two_df(df1, title1, df2, title2):\n",
    "    title_rule = '    {}'\n",
    "    data_rule = '        {0:30}'\n",
    "\n",
    "    # Euclidean distance of the ride and the taxi fare\n",
    "    print('Pearson correlation coef. of:')\n",
    "    print(title_rule.format('* dist and fare: '))\n",
    "    print(data_rule.format(title1), \\\n",
    "          df1['dist'].corr(df1['fare_amount']))\n",
    "    print(data_rule.format(title2), \\\n",
    "          df2['dist'].corr(df2['fare_amount']))\n",
    "\n",
    "    print(title_rule.format('* time of day and dist: '))\n",
    "    print(data_rule.format(title1), \\\n",
    "          df1['hour'].corr(df1['dist']))\n",
    "    print(data_rule.format(title2), \\\n",
    "          df2['hour'].corr(df2['dist']))\n",
    "\n",
    "    print(title_rule.format('* time of day and fare: '))\n",
    "    print(data_rule.format(title1), \\\n",
    "          df1['hour'].corr(df1['fare_amount']))\n",
    "    print(data_rule.format(title2), \\\n",
    "          df2['hour'].corr(df2['fare_amount']))\n",
    "\n",
    "#     fig = plt.figure(figsize=(32,32))\n",
    "#     ax1_1 = fig.add_subplot(321)\n",
    "#     ax2_1 = fig.add_subplot(322)\n",
    "#     ax1_2 = fig.add_subplot(323)\n",
    "#     ax2_2 = fig.add_subplot(324)\n",
    "#     ax1_3 = fig.add_subplot(325)\n",
    "#     ax2_3 = fig.add_subplot(326)\n",
    "\n",
    "#     df1.plot(ax=ax1_1, kind='scatter', x='dist', y='fare_amount', title = title1)\n",
    "#     df1.plot(ax=ax1_2, kind='scatter', x='dist', y='hour', title = title1)\n",
    "#     df1.plot(ax=ax1_3, kind='scatter', x='hour', y='fare_amount', title = title1)\n",
    "#     df2.plot(ax=ax2_1, kind='scatter', x='dist', y='fare_amount', title = title2)\n",
    "#     df2.plot(ax=ax2_2, kind='scatter', x='dist', y='hour', title = title2)\n",
    "#     df2.plot(ax=ax2_3, kind='scatter', x='hour', y='fare_amount', title = title2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fare(row_data):\n",
    "    \"\"\"\n",
    "    this is a soft cut based on initial chare $2.50 and the improvement surcharge 30-cent\n",
    "    \"\"\"\n",
    "    return row_data['fare_amount'] > 2.8\n",
    "\n",
    "def valid_transportation_region(row_data, left_bottom = LEFT_BOTTOM_BOUNDARY, right_top = RIGHT_TOP_BOUNDARY):\n",
    "    \"\"\"\n",
    "    default region based on the rectangle formed by Tennessee and Maine, \n",
    "    since it takes more than 12 hrs to drive from the boundary to NYC or\n",
    "    from NYC to the boundary\n",
    "    \"\"\"\n",
    "    return (row_data['pickup_longitude'] > left_bottom.longitude) & \\\n",
    "           (row_data['pickup_longitude'] < right_top.longitude) & \\\n",
    "           (row_data['dropoff_longitude'] > left_bottom.longitude) & \\\n",
    "           (row_data['dropoff_longitude'] < right_top.longitude) & \\\n",
    "            (row_data['pickup_latitude'] > left_bottom.latitude) & \\\n",
    "            (row_data['pickup_latitude'] < right_top.latitude) & \\\n",
    "            (row_data['dropoff_latitude'] > left_bottom.latitude) & \\\n",
    "            (row_data['dropoff_latitude'] < right_top.latitude)\n",
    "\n",
    "def valid_travel_location(row_data):\n",
    "    \"\"\"\n",
    "    pickup and dropoff should not be exactly the same or\n",
    "    both outside the NYC \n",
    "    \"\"\"\n",
    "    return (row_data['pickup_longitude'] != row_data['dropoff_longitude']) | \\\n",
    "           (row_data['pickup_latitude'] != row_data['dropoff_latitude']) | \\\n",
    "           (\\\n",
    "            (row_data['pickup_longitude'] >= NYC_LONGITUDE[0]) & \\\n",
    "            (row_data['pickup_longitude'] <= NYC_LONGITUDE[1]) & \\\n",
    "            (row_data['pickup_latitude'] >= NYC_LATITUDE[0]) & \\\n",
    "            (row_data['pickup_latitude'] <= NYC_LATITUDE[1]) \\\n",
    "           ) | (\\\n",
    "            (row_data['dropoff_longitude'] >= NYC_LONGITUDE[0]) & \\\n",
    "            (row_data['dropoff_longitude'] <= NYC_LONGITUDE[1]) & \\\n",
    "            (row_data['dropoff_latitude'] >= NYC_LATITUDE[0]) & \\\n",
    "            (row_data['dropoff_latitude'] <= NYC_LATITUDE[1]) \\\n",
    "           )\n",
    "\n",
    "def valid_passenger_count(row_data):\n",
    "    \"\"\"\n",
    "    by Taxi rule, the maximum capacity is 6\n",
    "    \"\"\"\n",
    "    return (row_data['passenger_count'] > 0) & (row_data['passenger_count'] <= 6)\n",
    "\n",
    "# def datetime_parser(x):\n",
    "#     print(x['pickup_datetime'])\n",
    "#     try:\n",
    "#         datetime_object = datetime.strptime(x['pickup_datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "#         return datetime_object.hours*60 + datetime_object.minutes\n",
    "#     except:\n",
    "#         return pd.NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fare_amount_judge_by_travel_distance(row_data):\n",
    "    return valid_fare_amount_with_long_distance(row_data) & \\\n",
    "           valid_fare_amount_with_short_distance(row_data)\n",
    "\n",
    "def valid_fare_amount_with_long_distance(row_data):\n",
    "    return row_data['fare_amount'] >= (row_data['dist'] * MILEAGE + 2.8)\n",
    "\n",
    "def valid_fare_amount_with_short_distance(row_data):\n",
    "    return (row_data['dist'] >= 0.2) | (row_data['fare_amount'] <= 10)\n",
    "\n",
    "def valid_fare_with_upperbound(row_data, amount = 500):\n",
    "    return row_data['fare_amount'] < amount\n",
    "    \n",
    "def to_jfk(row_data):\n",
    "    if ((row_data['dropoff_longitude'] >= JFK_LONGITUDE[0]) & \\\n",
    "       (row_data['dropoff_longitude'] <= JFK_LONGITUDE[1]) & \\\n",
    "       (row_data['dropoff_latitude'] >= JFK_LATITUDE[0]) & \\\n",
    "       (row_data['dropoff_latitude'] <= JFK_LATITUDE[1])):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def from_jfk(row_data):\n",
    "    if ((row_data['pickup_longitude'] >= JFK_LONGITUDE[0]) & \\\n",
    "        (row_data['pickup_longitude'] <= JFK_LONGITUDE[1]) & \\\n",
    "        (row_data['pickup_latitude'] >= JFK_LATITUDE[0]) & \\\n",
    "        (row_data['pickup_latitude'] <= JFK_LATITUDE[1])):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def remove_outliers_Tukey(usefulData, attr):\n",
    "    thirdQuartile = usefulData.quantile(.75)[attr]\n",
    "    firstQuartile = usefulData.quantile(.25)[attr]\n",
    "    IQR = thirdQuartile - firstQuartile\n",
    "    return usefulData[usefulData[attr].between(firstQuartile - (IQR * 1.5), thirdQuartile + (IQR * 1.5))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = basic_filter_df.pickup_latitude.values\n",
    "lon = basic_filter_df.pickup_longitude.values\n",
    "# population = cities['population_total'].values\n",
    "# area = cities['area_total_km2'].values\n",
    "\n",
    "NYC_LONGITUDE = (-74.256436, -73.699733)\n",
    "NYC_LATITUDE = (40.495029, 40.915592)\n",
    "\n",
    "m = Basemap(projection='merc', lat_0 = 40.5, lon_0 = -75, resolution = 'h', area_thresh = 0.1,\n",
    "    llcrnrlon=-80, llcrnrlat=35,\n",
    "    urcrnrlon=-65, urcrnrlat=45)\n",
    "\n",
    "m.drawmapboundary(fill_color='aqua')\n",
    "m.fillcontinents(color='#ddaa66',lake_color='aqua')\n",
    "m.drawcoastlines()\n",
    "\n",
    "x,y = m(lon, lat)\n",
    "\n",
    "m.plot(x, y, 'ro', markersize=1)\n",
    "\n",
    "m.shadedrelief()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# https://peak5390.wordpress.com/2012/12/08/matplotlib-basemap-tutorial-plotting-points-on-a-simple-map/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust or Create Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "def dist(row_data):\n",
    "    R = 6373.0\n",
    "    s_lon = radians(row_data['pickup_longitude'])\n",
    "    s_lat = radians(row_data['pickup_latitude'])\n",
    "    e_lon = radians(row_data['dropoff_longitude'])\n",
    "    e_lat = radians(row_data['dropoff_latitude'])\n",
    "    diff_lon = e_lon - s_lon\n",
    "    diff_lat = e_lat - s_lat\n",
    "\n",
    "    a = sin(diff_lat / 2)**2 + cos(s_lat) * cos(e_lat) * sin(diff_lon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    return R * c * 0.621371\n",
    "\n",
    "def dist_by_geopy(row_data):\n",
    "    s_lon = row_data['pickup_longitude']\n",
    "    s_lat = row_data['pickup_latitude']\n",
    "    e_lon = row_data['dropoff_longitude']\n",
    "    e_lat = row_data['dropoff_latitude']\n",
    "    return geodesic((s_lon, s_lat), (e_lon, e_lat)).miles\n",
    "\n",
    "# clean_data['dist'] = np.vectorize(dist)(clean_data['pickup_longitude'], clean_data['pickup_latitude'], clean_data['dropoff_longitude'], clean_data['dropoff_latitude'])\n",
    "# https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude/19412565\n",
    "\n",
    "def insert_est_or_edt_time(df):\n",
    "    df.insert(df.shape[1],'new_york_time',\n",
    "              df.pickup_datetime.dt.tz_localize('utc').\\\n",
    "              dt.tz_convert('America/New_York'))\n",
    "    \n",
    "def insert_year(df):\n",
    "    df.insert(df.shape[1], 'year', df.new_york_time.dt.year)\n",
    "\n",
    "def insert_weekday(df):\n",
    "    df.insert(df.shape[1], 'weekday', df.new_york_time.dt.weekday)\n",
    "\n",
    "def insert_time_of_day(df):\n",
    "    df.insert(df.shape[1], 'hour', df.new_york_time.dt.hour + df.new_york_time.dt.minute/60)\n",
    "\n",
    "# def insert_dist(df, func = dist):\n",
    "#     euclidean_dist = df.apply(func, axis = 1)\n",
    "#     df.insert(df.shape[1], 'dist', euclidean_dist)\n",
    "    \n",
    "def insert_feature(df, func = None, feature_name = None):\n",
    "    new_data = df.apply(func, axis = 1)\n",
    "    df.insert(df.shape[1], feature_name, new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression(df, test_size = 0.3):\n",
    "    train, test = train_test_split(df, test_size = test_size)\n",
    "    train_x = list(map(lambda x: [x], list(train.dist)))\n",
    "    train_y = list(map(lambda x: [x], list(train.fare_amount)))\n",
    "    test_x = list(map(lambda x: [x], list(test.dist)))\n",
    "    test_y = list(map(lambda x: [x], list(test.fare_amount)))\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(train_x, train_y)\n",
    "    fare_predict = regr.predict(test_x)\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    # The mean squared error\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "          % mean_squared_error(test_y, fare_predict))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % r2_score(test_y, fare_predict))\n",
    "\n",
    "    # Plot outputs\n",
    "    plt.scatter(test_x, test_y,  color='blue')\n",
    "    plt.plot(test_x, fare_predict, color='red', linewidth=3)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_fare(row_data):\n",
    "    fare = row_data['fare_amount']\n",
    "    \n",
    "    if to_jfk(row_data): # should consider from_jfk too \n",
    "        # flat fare of $52\n",
    "        fare -= 52\n",
    "        # MTA State Surcharge\n",
    "        fare -= 0.5\n",
    "        # 30-cent Improvement Surcharge,\n",
    "        fare -= 0.3\n",
    "        \n",
    "        if is_rush(row_data):\n",
    "            fare -= 4.5\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Take a look at the training data ...\n",
    "\n",
    "## There may be anomalies in the data that you may need to factor in before you start on the other tasks. Clean the data first to handle these issues. Explain what you did to clean the data (in bulleted form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation Coefficients, \n",
    "## and Visualization of the Relation between the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_df = basic_filter_df.loc[valid_fare_amount_judge_by_travel_distance(basic_filter_df)]\n",
    "advanced_w_upperbound = advanced_df[valid_fare_with_upperbound(advanced_df, 300)]\n",
    "\n",
    "compare_two_df(basic_filter_df, 'Applied basic rules', advanced_df, 'Applied travel distance rules')\n",
    "compare_two_df(advanced_df, 'Applied travel distance rules', advanced_w_upperbound, 'Applied upperbound fare rule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "basic_filter_df.fare_amount.hist(ax = ax, bottom=0.01)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "advanced_w_upperbound.fare_amount.hist(ax = ax, bottom=0.01)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_filter_df.loc[basic_filter_df.fare_amount > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = advanced_w_upperbound[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(series, bins = 5, log = True):\n",
    "    fig, ax = plt.subplots()\n",
    "    series.hist(bins = bins, ax = ax, bottom=0.0001)\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "    ticks = [val for val in range(bins)]\n",
    "    plt.setp(ax, xticks=ticks)\n",
    "\n",
    "# Use the pyplot interface to change just one subplot...\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weekday(row_data):\n",
    "    return row_data['weekday'] < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekday\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays_df = base_df.loc[weekdays(base_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "weekdays_df.fare_amount.hist(ax = ax, bottom=0.01)\n",
    "ax.set_yscale('log')\n",
    "# weekdays_df.weekday.hist(bins=5, grid = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.hist(weekdays_df.weekday, bins=5)\n",
    "plt.xticks(range(5))\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekends_df = base_df.loc[~weekdays(base_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekends_df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create New Feature\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_feature(base_df, func = to_jfk, feature_name = 'to_jfk')\n",
    "insert_feature(base_df, func = from_jfk, feature_name = 'from_jfk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_from_jfk_res = base_df.apply(to_from_jfk, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_two_df(base_df, 'base case', weekdays_df, 'weekday only')\n",
    "# compare_two_df(base_df, 'base case', weekends_df, 'weekend only')\n",
    "# compare_two_df(base_df, 'base case', jfk_df, 'jfk only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_feature(base_df, func = dist, feature_name = 'dist2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_linear_regression(advanced_filter_df)\n",
    "to_or_from_jfk_df = base_df.loc[(base_df['to_jfk'] == 1) | (base_df['from_jfk'] == 1)]\n",
    "to_jfk_df = base_df.loc[(base_df['to_jfk'] == 1) & (base_df['from_jfk'] == 0)]\n",
    "from_jfk_df = base_df.loc[(base_df['to_jfk'] == 0) & (base_df['from_jfk'] == 1)]\n",
    "not_in_jfk_df = base_df.loc[(base_df['to_jfk'] == 0) & (base_df['from_jfk'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_linear_regression(advanced_w_upperbound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Anywhere to JFK\n",
    "* assume anywhere $\\in$ Manhattan\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From JFK to Anywhere\n",
    "\n",
    "* assume anywhere $\\in$ Manhattan\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_pearson_corr_result(advanced_filter_df, 'Applied advanced filter')\n",
    "# basic_visualization_result(advanced_filter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced_w_upperbound.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_dist = test_df.apply(dist, axis=1)\n",
    "# test_df.insert(test_df.shape[1], 'dist', test_df_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_X = list(map(lambda x: [x], list(test_df.dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare_predict = regr.predict(test_X).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'key': test_df.key,\\\n",
    "#                            'fare_amount': fare_predict.ravel()},\\\n",
    "#                           columns = ['key', 'fare_amount'])\n",
    "# submission.to_csv('submission.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Features \n",
    "## By year\n",
    "## By weekday\n",
    "## By time_of_day (hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Features - Adjusted_Fare_Amount_By_Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = list(advanced_filter_df.columns.values)\n",
    "\n",
    "# for header in headers:\n",
    "#     print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = zip(list(advanced_filter_df.columns.values), list(base_filter_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h1, h2 in headers:\n",
    "#     print('{:30}, {:30}'.format(h1, h2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years_df = [None for _ in range(min(clean_data.year), max(clean_data.year) + 1)]\n",
    "# minimum_year = min(clean_data.year)\n",
    "\n",
    "# years = max(clean_data.year) + 1 - minimum_year\n",
    "# for year in range(years):\n",
    "#     years_df[year] = clean_data[clean_data.year == minimum_year+year]\n",
    "      \n",
    "#     train, test = train_test_split(years_df[year], test_size=0.2)\n",
    "#     train_x = list(map(lambda x: [x], list(train.dist)))\n",
    "#     train_y = list(map(lambda x: [x], list(train.fare_amount)))\n",
    "#     test_x = list(map(lambda x: [x], list(test.dist)))\n",
    "#     test_y = list(map(lambda x: [x], list(test.fare_amount)))\n",
    "#     regr.fit(train_x, train_y)\n",
    "#     fare_predict = regr.predict(test_x)\n",
    "\n",
    "#     print(years_df[year]['dist'].corr(years_df[year]['fare_amount']))\n",
    "#     # The coefficients\n",
    "#     print('Year: {}'.format(minimum_year + year), 'Coeff: ', regr.coef_, \\\n",
    "#           \"M.S.E: %.2f\" % (mean_squared_error(test_y, fare_predict)), \\\n",
    "#           'Variance score: %.2f' % r2_score(test_y, fare_predict))\n",
    "#     print('\\n')\n",
    "\n",
    "    # Plot outputs\n",
    "#     plt.scatter(test_x, test_y,  color='blue')\n",
    "#     plt.plot(test_x, fare_predict, color='red', linewidth=3)\n",
    "\n",
    "#     plt.xticks(())\n",
    "#     plt.yticks(())\n",
    "\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Night Surcharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def night_surcharge(row_data, night = True):\n",
    "#     if night:\n",
    "#         return (row_data['hour'] >= 20) | (row_data['hour'] <= 6)\n",
    "#     else:\n",
    "#         return (row_data['hour'] < 20) & (row_data['hour'] > 6)\n",
    "    \n",
    "# def weekday_filter(row_data):\n",
    "#     return row_data.weekday < 5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in range(years):\n",
    "#     night = None\n",
    "#     night = years_df[year][night_surcharge(years_df[year], True)]\n",
    "#     train, test = train_test_split(night, test_size=0.2)\n",
    "#     train_x = list(map(lambda x: [x], list(train.dist)))\n",
    "#     train_y = list(map(lambda x: [x], list(train.fare_amount)))\n",
    "#     test_x = list(map(lambda x: [x], list(test.dist)))\n",
    "#     test_y = list(map(lambda x: [x], list(test.fare_amount)))\n",
    "#     regr.fit(train_x, train_y)\n",
    "#     fare_predict = regr.predict(test_x)\n",
    "\n",
    "#     print(night['dist'].corr(night['fare_amount']))\n",
    "#     # The coefficients\n",
    "#     print('Year: {}'.format(minimum_year + year), 'Coeff: ', regr.coef_, \\\n",
    "#           \"M.S.E: %.2f\" % (mean_squared_error(test_y, fare_predict)), \\\n",
    "#           'Variance score: %.2f' % r2_score(test_y, fare_predict))\n",
    "#     print('\\n')\n",
    "\n",
    "    # Plot outputs\n",
    "#     plt.scatter(test_x, test_y,  color='blue')\n",
    "#     plt.plot(test_x, fare_predict, color='red', linewidth=3)\n",
    "\n",
    "#     plt.xticks(())\n",
    "#     plt.yticks(())\n",
    "\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in range(years):\n",
    "#     flag = [True, False]\n",
    "#     weekday = None\n",
    "#     weekday = years_df[year][weekday_filter(years_df[year])]\n",
    "#     train, test = train_test_split(weekday, test_size=0.2)\n",
    "#     train_x = list(map(lambda x: [x], list(train.dist)))\n",
    "#     train_y = list(map(lambda x: [x], list(train.fare_amount)))\n",
    "#     test_x = list(map(lambda x: [x], list(test.dist)))\n",
    "#     test_y = list(map(lambda x: [x], list(test.fare_amount)))\n",
    "#     regr.fit(train_x, train_y)\n",
    "#     fare_predict = regr.predict(test_x)\n",
    "\n",
    "#     print(weekday['dist'].corr(weekday['fare_amount']))\n",
    "#     # The coefficients\n",
    "#     print('Year: {}'.format(minimum_year + year), 'Coeff: ', regr.coef_, \\\n",
    "#           \"M.S.E: %.2f\" % (mean_squared_error(test_y, fare_predict)), \\\n",
    "#           'Variance score: %.2f' % r2_score(test_y, fare_predict))\n",
    "#     print('\\n')\n",
    "\n",
    "#     # Plot outputs\n",
    "#     plt.scatter(test_x, test_y,  color='blue')\n",
    "#     plt.plot(test_x, fare_predict, color='red', linewidth=3)\n",
    "\n",
    "#     plt.xticks(())\n",
    "#     plt.yticks(())\n",
    "\n",
    "    \n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
